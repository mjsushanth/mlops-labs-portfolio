{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c2147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup - ALL IN ONE CELL TO RUN AND WALK AWAY\n",
    "\"\"\"\n",
    "Complete RAG Pipeline Test\n",
    "Run this cell and take a break - it handles everything\n",
    "\"\"\"\n",
    "\n",
    "# Fix path issues for notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from qdrant_client import QdrantClient\n",
    "import pandas as pd\n",
    "import logging\n",
    "import polars as pl\n",
    "\n",
    "# Handle both local and Docker environments\n",
    "if os.path.exists('/opt/airflow/plugins'):\n",
    "    # Running in Docker\n",
    "    sys.path.insert(0, '/opt/airflow/plugins')\n",
    "    DATA_PATH = Path('/opt/airflow/data/exports')\n",
    "else:\n",
    "    # Running locally - adjust this path to YOUR structure\n",
    "    notebook_dir = Path.cwd()\n",
    "    project_root = notebook_dir.parent  # Go up from notebooks/ to project root\n",
    "    sys.path.insert(0, str(project_root / 'plugins'))\n",
    "    DATA_PATH = project_root / 'data' / 'exports'\n",
    "\n",
    "# For autoreload in notebook (optional but helpful)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c90eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:rag_utils:Running in Local environment\n",
      "INFO:rag_utils:Data path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 18008\\MasterRepo & LabRepo\\mlops-labs-portfolio\\Airflow_Docker_VDB_Lab\\data\\exports\\sec_filings_small_full.parquet\n",
      "INFO:rag_utils:Qdrant host: localhost\n",
      "INFO:rag_utils:Loaded 200000 total sentences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n",
      "\n",
      "==================================================\n",
      "STEP 1: Testing with 100 sentences first\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_utils:Using all 191418 sentences\n",
      "INFO:rag_utils:Created 90 chunks from 100 sentences\n",
      "INFO:rag_utils:Chunk stats - Min chars: 17, Max: 1431, Avg: 238\n",
      "INFO:rag_utils:Loading embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:rag_utils:First run downloads ~420MB model - cached for future use\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 191418 total sentences\n",
      "Using 100 sentences for test\n",
      "Created 90 chunks from sample\n",
      "\n",
      "Generating embeddings for sample (30 seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:rag_utils:Model max sequence length: 384 tokens\n",
      "INFO:rag_utils:Generating embeddings for 90 chunks (batch_size=8)\n",
      "INFO:rag_utils:Expected time: ~25-35 minutes for 70k chunks\n",
      "Batches: 100%|██████████| 12/12 [00:04<00:00,  2.47it/s]\n",
      "INFO:rag_utils:Generated 90 embeddings of dimension 768\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:Collection sec_filings_test exists with 90 points\n",
      "INFO:rag_utils:Keeping existing collection (dimensions match)\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 90 embeddings\n",
      "\n",
      "Connected to Qdrant. Existing collections: 1\n",
      "\n",
      "Storing sample in test collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:Collection sec_filings_test exists with 90 points\n",
      "INFO:rag_utils:Keeping existing collection (dimensions match)\n",
      "INFO:rag_utils:Preparing to upsert 90 chunks to Qdrant...\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_test/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:Collection 'sec_filings_test' now has 180 vectors\n",
      "INFO:rag_utils:Data persisted in ./qdrant_storage/\n",
      "INFO:rag_utils:\n",
      "==================================================\n",
      "INFO:rag_utils:Testing retrieval with query: 'What are the main business risks?'\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 90 chunks in test collection\n",
      "\n",
      "Testing retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.82it/s]\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sec_filings_test/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:\n",
      "Top 3 Results:\n",
      "INFO:rag_utils:--------------------------------------------------------------------------------\n",
      "INFO:rag_utils:--------------------------------------------------------------------------------\n",
      "INFO:rag_utils:Search completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. [Score: 0.4613]\n",
      "   Company: ADVANCED MICRO DEVICES INC\n",
      "   Section: 8 (MD&A)\n",
      "   Date: 2015-12-26\n",
      "   Priority: high\n",
      "   Text Preview: Potential events or circumstance that could reasonably be expected to negatively affect the key assumptions we used in estimating the fair value of our reporting units include adverse changes in our industry, increased competition, an inability to successfully introduce new products in the marketpla...\n",
      "   Chunk ID: 0000002488_10-K_2015_sec8_full\n",
      "\n",
      "2. [Score: 0.4613]\n",
      "   Company: ADVANCED MICRO DEVICES INC\n",
      "   Section: 8 (MD&A)\n",
      "   Date: 2015-12-26\n",
      "   Priority: high\n",
      "   Text Preview: Potential events or circumstance that could reasonably be expected to negatively affect the key assumptions we used in estimating the fair value of our reporting units include adverse changes in our industry, increased competition, an inability to successfully introduce new products in the marketpla...\n",
      "   Chunk ID: 0000002488_10-K_2015_sec8_full\n",
      "\n",
      "3. [Score: 0.4594]\n",
      "   Company: CECO ENVIRONMENTAL CORP\n",
      "   Section: 8 (MD&A)\n",
      "   Date: 2004-12-31\n",
      "   Priority: high\n",
      "   Text Preview: We wish to caution investors that other factors might, in the future, prove to be important in affecting our results of operations....\n",
      "   Chunk ID: 0000003197_10-K_2004_sec8_full\n",
      "Found 3 results - search working!\n",
      "\n",
      "==================================================\n",
      "VALIDATION COMPLETE - All systems working!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now imports should work\n",
    "from rag_utils import (\n",
    "    load_and_enrich_data,\n",
    "    create_smart_chunks,\n",
    "    generate_embeddings_batch,\n",
    "    init_qdrant_collection,\n",
    "    upsert_to_qdrant,\n",
    "    test_retrieval\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"Imports successful\")\n",
    "\n",
    "# --- QUICK VALIDATION SECTION ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 1: Testing with 100 sentences first\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load and sample\n",
    "df = load_and_enrich_data(min_tokens=3)\n",
    "print(f\"Loaded {len(df)} total sentences\")\n",
    "\n",
    "df_sample = df.sample(100, seed=42)\n",
    "print(f\"Using {len(df_sample)} sentences for test\")\n",
    "\n",
    "# Create chunks\n",
    "chunks = create_smart_chunks(df_sample, window_size=3, stride=2)\n",
    "print(f\"Created {len(chunks)} chunks from sample\")\n",
    "\n",
    "# Generate embeddings for sample\n",
    "print(\"\\nGenerating embeddings for sample (30 seconds)...\")\n",
    "chunks_with_embeddings = generate_embeddings_batch(\n",
    "    chunks, \n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    batch_size=8\n",
    ")\n",
    "print(f\"Generated {len(chunks_with_embeddings)} embeddings\")\n",
    "\n",
    "# Test Qdrant connection\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "try:\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    collections = client.get_collections()\n",
    "    print(f\"\\nConnected to Qdrant. Existing collections: {len(collections.collections)}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Cannot connect to Qdrant: {e}\")\n",
    "    print(\"Make sure docker-compose is running!\")\n",
    "    raise\n",
    "\n",
    "# Store sample in test collection\n",
    "print(\"\\nStoring sample in test collection...\")\n",
    "test_collection = \"sec_filings_test\"\n",
    "client = init_qdrant_collection(collection_name=test_collection, vector_size=768)\n",
    "client = upsert_to_qdrant(chunks_with_embeddings, collection_name=test_collection)\n",
    "print(f\"Stored {len(chunks_with_embeddings)} chunks in test collection\")\n",
    "\n",
    "# Test retrieval\n",
    "print(\"\\nTesting retrieval...\")\n",
    "results = test_retrieval(query=\"What are the main business risks?\", n_results=3, collection_name=\"sec_filings_test\")\n",
    "print(f\"Found {len(results)} results - search working!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION COMPLETE - All systems working!\")\n",
    "print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee12811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sec_filings_test/points/scroll \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/sec_filings_test/points/scroll \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections (tables):\n",
      "  sec_filings_test: 180 vectors\n",
      "\n",
      "sec_filings_test: 180 total vectors\n",
      "Vector dimensions: 768\n",
      "\n",
      "First 5 records:\n",
      "ID: 118610\n",
      "  Company: ADVANCED MICRO DEVICES INC\n",
      "  Section: 8\n",
      "  Text preview: Historically, the ATI business had lower gross mar...\n",
      "ID: 1903369\n",
      "  Company: ADVANCED MICRO DEVICES INC\n",
      "  Section: 9\n",
      "  Text preview: During the first quarter of 2011, we reassessed ou...\n",
      "ID: 2400525\n",
      "  Company: ACME UNITED CORP\n",
      "  Section: 8\n",
      "  Text preview: MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL ...\n",
      "ID: 2947496\n",
      "  Company: ABBOTT LABORATORIES\n",
      "  Section: 0\n",
      "  Text preview: Abbott retained the branded generics pharmaceutica...\n",
      "ID: 3112637\n",
      "  Company: BK Technologies Corp\n",
      "  Section: 8\n",
      "  Text preview: In July 2015, the FASB issued ASU 2015-11, “Simpli...\n",
      "\n",
      "Found 10 records with section=8\n",
      "\n",
      "Collection Stats:\n",
      "  Vectors: 180\n",
      "  Indexed: 0\n",
      "  Status: green\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Qdrant Database Operations\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# 1. Show all collections (like SHOW TABLES)\n",
    "collections = client.get_collections().collections\n",
    "print(\"Collections (tables):\")\n",
    "for col in collections:\n",
    "    info = client.get_collection(col.name)\n",
    "    print(f\"  {col.name}: {info.points_count} vectors\")\n",
    "\n",
    "# 2. Count vectors in specific collection (like SELECT COUNT(*))\n",
    "collection_name = \"sec_filings_test\"  # Change to your collection\n",
    "try:\n",
    "    info = client.get_collection(collection_name)\n",
    "    print(f\"\\n{collection_name}: {info.points_count} total vectors\")\n",
    "    print(f\"Vector dimensions: {info.config.params.vectors.size}\")\n",
    "except:\n",
    "    print(f\"Collection {collection_name} doesn't exist\")\n",
    "\n",
    "# 3. Get sample records (like SELECT * LIMIT 5)\n",
    "if info.points_count > 0:\n",
    "    records = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=5\n",
    "    )[0]  # Returns (records, next_offset)\n",
    "    \n",
    "    print(f\"\\nFirst 5 records:\")\n",
    "    for record in records:\n",
    "        print(f\"ID: {record.id}\")\n",
    "        print(f\"  Company: {record.payload.get('company')}\")\n",
    "        print(f\"  Section: {record.payload.get('section')}\")\n",
    "        print(f\"  Text preview: {record.payload.get('text', '')[:50]}...\")\n",
    "\n",
    "# 4. Query with filters (like SELECT * WHERE section=8)\n",
    "filtered = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"section\",\n",
    "                match=MatchValue(value=8)\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=10\n",
    ")[0]\n",
    "print(f\"\\nFound {len(filtered)} records with section=8\")\n",
    "\n",
    "# 5. Get collection statistics\n",
    "stats = client.get_collection(collection_name)\n",
    "print(f\"\\nCollection Stats:\")\n",
    "print(f\"  Vectors: {stats.points_count}\")\n",
    "print(f\"  Indexed: {stats.indexed_vectors_count}\")\n",
    "print(f\"  Status: {stats.status}\")\n",
    "\n",
    "# 6. Delete specific vectors (like DELETE WHERE)\n",
    "# client.delete(\n",
    "#     collection_name=collection_name,\n",
    "#     points_filter=Filter(\n",
    "#         must=[FieldCondition(key=\"company\", match=MatchValue(value=\"ACME CORP\"))]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e23223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 collections:\n",
      "  - sec_filings_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: DELETE http://localhost:6333/collections/sec_filings_test \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: sec_filings_test\n",
      "\n",
      "All collections deleted!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Delete All Collections\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "# Get all collections\n",
    "collections = client.get_collections().collections\n",
    "print(f\"Found {len(collections)} collections:\")\n",
    "for col in collections:\n",
    "    print(f\"  - {col.name}\")\n",
    "\n",
    "# Delete each collection\n",
    "for col in collections:\n",
    "    client.delete_collection(col.name)\n",
    "    print(f\"Deleted: {col.name}\")\n",
    "\n",
    "print(\"\\nAll collections deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772566bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_utils:Loaded 200000 total sentences\n",
      "INFO:rag_utils:Randomly sampled 2000 sentences\n",
      "INFO:rag_utils:Using 2000 sentences\n",
      "INFO:rag_utils:Created 989 chunks from 2000 sentences\n",
      "INFO:rag_utils:Chunk stats - Min chars: 12, Max: 2120, Avg: 373\n",
      "INFO:rag_utils:Split 4 long chunks (likely tables/lists)\n",
      "INFO:rag_utils:Loading embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:rag_utils:First run downloads ~420MB model - cached for future use\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:rag_utils:Model max sequence length: 384 tokens\n",
      "INFO:rag_utils:Generating embeddings for 989 chunks (batch_size=64)\n",
      "INFO:rag_utils:Expected time: ~25-35 minutes for 70k chunks\n",
      "Batches: 100%|██████████| 16/16 [01:23<00:00,  5.21s/it]\n",
      "INFO:rag_utils:Generated 989 embeddings of dimension 768\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:Created collection 'sec_filings_sample' with 768 dimensions\n",
      "INFO:rag_utils:Preparing to upsert 989 chunks to Qdrant...\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/sec_filings_sample/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:  Upserted 989/989 chunks...\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/sec_filings_sample \"HTTP/1.1 200 OK\"\n",
      "INFO:rag_utils:Collection 'sec_filings_sample' now has 989 vectors\n",
      "INFO:rag_utils:Data persisted in ./qdrant_storage/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qdrant_client.qdrant_client.QdrantClient at 0x2b6776db990>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Do pipeline for LAB, Perform with 5k sentences or lesser.\n",
    "\n",
    "from rag_utils import (\n",
    "    load_and_enrich_data,\n",
    "    create_smart_chunks,\n",
    "    generate_embeddings_batch,\n",
    "    init_qdrant_collection,\n",
    "    upsert_to_qdrant,\n",
    "    test_retrieval\n",
    ")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "df = load_and_enrich_data(min_tokens=3, sample_size=2000)\n",
    "\n",
    "chunks = create_smart_chunks(df)\n",
    "chunks_with_embeddings = generate_embeddings_batch(chunks, batch_size=64)\n",
    "upsert_to_qdrant(chunks_with_embeddings, collection_name=\"sec_filings_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaad8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b18a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f5d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa79429",
   "metadata": {},
   "source": [
    "## Validation complete earlier. Bottom Error - ignore.\n",
    "#### Bottom part was trying to force 95k embeddings and chunking, it was taking more than 5 hours potentially. Not needed.\n",
    "#### Wrote func to filter df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e2630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_utils:Loaded 200000 total sentences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ready for FULL PIPELINE?\n",
      "This will process:\n",
      "- 200,000 sentences\n",
      "- Create ~70,000 chunks\n",
      "- Generate embeddings (35 minutes)\n",
      "- Store in Qdrant (10 minutes)\n",
      "\n",
      "TOTAL TIME: ~45 minutes\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "STARTING FULL PIPELINE\n",
      "==================================================\n",
      "\n",
      "1. Loading all data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_utils:Using all 191418 sentences\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 191418 sentences\n",
      "\n",
      "2. Creating chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_utils:Created 94991 chunks from 191418 sentences\n",
      "INFO:rag_utils:Chunk stats - Min chars: 17, Max: 4850, Avg: 525\n",
      "INFO:rag_utils:Split 587 long chunks (likely tables/lists)\n",
      "INFO:rag_utils:Loading embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:rag_utils:First run downloads ~420MB model - cached for future use\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Created 94991 chunks\n",
      "\n",
      "3. Generating embeddings...\n",
      "   THIS WILL TAKE ~35 MINUTES\n",
      "   Started at: 06:54:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:rag_utils:Model max sequence length: 384 tokens\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_2004_sec19_chunk44_part1 has ~414 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_2004_sec19_chunk46_part1 has ~414 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2020_sec19_chunk18_part1 has ~672 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2015_sec0_chunk6_part1 has ~596 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2013_sec0_chunk4_part2 has ~394 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2014_sec0_chunk164_part1 has ~737 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2014_sec0_chunk166_part0 has ~737 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2011_sec0_chunk20_part1 has ~466 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2005_sec19_chunk68_part1 has ~405 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2007_sec0_chunk272_part1 has ~640 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2010_sec19_chunk10_part1 has ~424 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2010_sec19_chunk12_part0 has ~424 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2014_sec0_chunk6_part1 has ~589 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2012_sec0_chunk18_part1 has ~469 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2009_sec19_chunk4_part1 has ~438 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2009_sec19_chunk6_part0 has ~438 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2004_sec16_full has ~390 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2003_sec19_chunk78_part1 has ~408 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2003_sec19_chunk80_part0 has ~408 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_1997_sec10_chunk68_part1 has ~428 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_1997_sec10_chunk70_part0 has ~428 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2010_sec0_chunk6_part1 has ~492 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2010_sec0_chunk8_part0 has ~492 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2002_sec19_chunk14_part1 has ~608 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2002_sec19_chunk14_part2 has ~391 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2002_sec19_chunk16_part0 has ~391 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002186_10-K_2018_sec15_chunk134_part1 has ~440 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002186_10-K_2018_sec15_chunk136_part0 has ~440 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2004_sec19_chunk68_part1 has ~403 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2012_sec0_chunk4_part1 has ~395 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_1996_sec8_chunk102_part1 has ~433 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002098_10-K_1996_sec8_chunk104_part0 has ~433 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2008_sec19_chunk408_part1 has ~610 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2008_sec19_chunk0_part1 has ~401 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2019_sec19_chunk86_part1 has ~437 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2018_sec0_chunk2_part1 has ~410 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2018_sec0_chunk4_part0 has ~410 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2018_sec0_chunk4_part2 has ~455 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2018_sec0_chunk6_part0 has ~455 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2018_sec0_chunk6_part1 has ~543 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2017_sec0_chunk4_part2 has ~388 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2017_sec0_chunk6_part0 has ~388 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2017_sec0_chunk6_part1 has ~598 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000002488_10-K_2016_sec0_chunk6_part1 has ~681 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001800_10-K_2007_sec19_chunk78_part1 has ~423 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2013_sec0_chunk8_part1 has ~570 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2013_sec0_chunk10_part0 has ~570 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec0_chunk12_part1 has ~665 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec0_chunk14_part0 has ~665 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2005_sec16_full has ~422 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2013_sec19_chunk2_part1 has ~441 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2012_sec19_chunk2_part1 has ~413 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec19_chunk54_part1 has ~402 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec19_chunk56_part0 has ~402 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec19_chunk426_part1 has ~413 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000003197_10-K_2009_sec19_chunk428_part0 has ~413 tokens, will be truncated\n",
      "WARNING:rag_utils:Chunk 0000001750_10-K_2014_sec19_chunk2_part1 has ~389 tokens, will be truncated\n",
      "WARNING:rag_utils:57/94991 chunks exceed token limit\n",
      "INFO:rag_utils:Generating embeddings for 94991 chunks (batch_size=16)\n",
      "INFO:rag_utils:Expected time: ~25-35 minutes for 70k chunks\n",
      "Batches:  14%|█▍        | 818/5937 [38:29<4:00:54,  2.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   THIS WILL TAKE ~35 MINUTES\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Started at:\u001b[39m\u001b[33m\"\u001b[39m, pd.Timestamp.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m chunks_with_embeddings_full = \u001b[43mgenerate_embeddings_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunks_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentence-transformers/all-mpnet-base-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks_with_embeddings_full)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Completed at:\u001b[39m\u001b[33m\"\u001b[39m, pd.Timestamp.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 18008\\MasterRepo & LabRepo\\mlops-labs-portfolio\\Airflow_Docker_VDB_Lab\\plugins\\rag_utils.py:300\u001b[39m, in \u001b[36mgenerate_embeddings_batch\u001b[39m\u001b[34m(chunks, model_name, batch_size)\u001b[39m\n\u001b[32m    297\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks (batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    298\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mExpected time: ~25-35 minutes for 70k chunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m embeddings = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    306\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Attach embeddings to chunks\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chunks, embeddings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:284\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[39m\n\u001b[32m    281\u001b[39m features = batch_to_device(features, device)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_value == \u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    287\u001b[39m         embeddings = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:98\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[32m     96\u001b[39m     trans_features[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m] = features[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m output_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m output_tokens = output_states[\u001b[32m0\u001b[39m]\n\u001b[32m    101\u001b[39m features.update({\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m: output_tokens, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m: features[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m]})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:551\u001b[39m, in \u001b[36mMPNetModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    549\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    550\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(input_ids=input_ids, position_ids=position_ids, inputs_embeds=inputs_embeds)\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    560\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:341\u001b[39m, in \u001b[36mMPNetEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    339\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:300\u001b[39m, in \u001b[36mMPNetLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    293\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m     **kwargs,\n\u001b[32m    299\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    308\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:241\u001b[39m, in \u001b[36mMPNetAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    234\u001b[39m     hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    239\u001b[39m     **kwargs,\n\u001b[32m    240\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.LayerNorm(\u001b[38;5;28mself\u001b[39m.dropout(self_outputs[\u001b[32m0\u001b[39m]) + hidden_states)\n\u001b[32m    249\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:170\u001b[39m, in \u001b[36mMPNetSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m q = \u001b[38;5;28mself\u001b[39m.q(hidden_states)\n\u001b[32m    169\u001b[39m k = \u001b[38;5;28mself\u001b[39m.k(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m q = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(q)\n\u001b[32m    173\u001b[39m k = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(k)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1525\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1526\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1530\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joems\\miniconda3\\envs\\airflow_qdrant_lab\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- DECISION POINT ---\n",
    "print(\"\\nReady for FULL PIPELINE?\")\n",
    "print(\"This will process:\")\n",
    "print(\"- 200,000 sentences\")\n",
    "print(\"- Create ~70,000 chunks\")\n",
    "print(\"- Generate embeddings (35 minutes)\")\n",
    "print(\"- Store in Qdrant (10 minutes)\")\n",
    "print(\"\\nTOTAL TIME: ~45 minutes\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Auto-proceed (comment out if you want manual confirmation)\n",
    "proceed = \"YES\"  # Change to \"NO\" to skip full pipeline\n",
    "\n",
    "if proceed == \"YES\":\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING FULL PIPELINE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Load all data\n",
    "    print(\"\\n1. Loading all data...\")\n",
    "    df_full = load_and_enrich_data(min_tokens=3)\n",
    "    print(f\"   Loaded {len(df_full)} sentences\")\n",
    "    \n",
    "    # 2. Create all chunks\n",
    "    print(\"\\n2. Creating chunks...\")\n",
    "    chunks_full = create_smart_chunks(df_full, window_size=3, stride=2)\n",
    "    print(f\"   Created {len(chunks_full)} chunks\")\n",
    "    \n",
    "    # 3. Generate embeddings (LONG PROCESS)\n",
    "    print(\"\\n3. Generating embeddings...\")\n",
    "    print(\"   THIS WILL TAKE ~35 MINUTES\")\n",
    "    print(\"   Started at:\", pd.Timestamp.now().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    chunks_with_embeddings_full = generate_embeddings_batch(\n",
    "        chunks_full,\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        batch_size=16\n",
    "    )\n",
    "    \n",
    "    print(f\"   Generated {len(chunks_with_embeddings_full)} embeddings\")\n",
    "    print(\"   Completed at:\", pd.Timestamp.now().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # 4. Store in Qdrant\n",
    "    print(\"\\n4. Storing in Qdrant...\")\n",
    "    print(\"   THIS WILL TAKE ~10 MINUTES\")\n",
    "    \n",
    "    client = upsert_to_qdrant(\n",
    "        chunks_with_embeddings_full,\n",
    "        collection_name=\"sec_filings\"  # Real collection name\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 5. Final verification\n",
    "    print(\"\\nFinal verification...\")\n",
    "    final_results = test_retrieval(\n",
    "        query=\"revenue growth factors\",\n",
    "        n_results=5\n",
    "    )\n",
    "    print(f\"Retrieval test successful - {len(final_results)} results found\")\n",
    "    \n",
    "    # Check collection stats\n",
    "    info = client.get_collection(\"sec_filings\")\n",
    "    print(f\"\\nCollection statistics:\")\n",
    "    print(f\"  Total vectors: {info.points_count}\")\n",
    "    print(f\"  Vector dimensions: {info.config.params.vectors.size}\")\n",
    "    print(f\"  Distance metric: {info.config.params.vectors.distance}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ALL DONE - Embeddings stored in ./qdrant_storage/\")\n",
    "    print(\"Data persists even after Docker restart\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "else:\n",
    "    print(\"Skipped full pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aceb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LATERRRR.\n",
    "\n",
    "# Cell 2: Verify Persistence (RUN SEPARATELY AFTER RESTART)\n",
    "\"\"\"\n",
    "Run this cell after docker-compose restart to verify persistence\n",
    "\"\"\"\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "collections = client.get_collections().collections\n",
    "\n",
    "print(\"Collections in Qdrant:\")\n",
    "for collection in collections:\n",
    "    info = client.get_collection(collection.name)\n",
    "    print(f\"  {collection.name}: {info.points_count} vectors\")\n",
    "\n",
    "# Test search still works\n",
    "if any(c.name == \"sec_filings\" for c in collections):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    query = \"What are the main risk factors?\"\n",
    "    query_embedding = model.encode(query, normalize_embeddings=True).tolist()\n",
    "    \n",
    "    results = client.search(\n",
    "        collection_name=\"sec_filings\",\n",
    "        query_vector=query_embedding,\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSearch test: Found {len(results)} results\")\n",
    "    print(\"Data successfully persisted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc66ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b33747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ca558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d539ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow_qdrant_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
