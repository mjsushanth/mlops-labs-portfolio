{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a772fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 18008\\MasterRepo & LabRepo\\mlops-labs-portfolio\\FlaskGCP_Lab\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Added to path: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc19b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path': 'D:\\\\JoelDesktop folds_24\\\\NEU FALL2025\\\\MLops IE7374 18008\\\\MasterRepo & LabRepo\\\\mlops-labs-portfolio\\\\FlaskGCP_Lab\\\\data\\\\exports\\\\sec_filings_small_full.parquet', 'size_mb': 16.54, 'exists': True, 'pandas_loaded': False, 'polars_loaded': False}\n",
      "Loading Pandas DataFrame from D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 18008\\MasterRepo & LabRepo\\mlops-labs-portfolio\\FlaskGCP_Lab\\data\\exports\\sec_filings_small_full.parquet...\n",
      "Loaded 200,000 rows into Pandas\n",
      "Pandas shape: (200000, 19)\n",
      "Loading Polars DataFrame from D:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 18008\\MasterRepo & LabRepo\\mlops-labs-portfolio\\FlaskGCP_Lab\\data\\exports\\sec_filings_small_full.parquet...\n",
      "Loaded 200,000 rows into Polars\n",
      "Polars shape: (200000, 19)\n",
      "Same object? True\n"
     ]
    }
   ],
   "source": [
    "# Data loader testing:\n",
    "from src.data_loader import get_pandas_data, get_polars_data, get_info\n",
    "print(get_info())\n",
    "\n",
    "df_pd = get_pandas_data()\n",
    "print(f\"Pandas shape: {df_pd.shape}\")\n",
    "df_pl = get_polars_data()\n",
    "print(f\"Polars shape: {df_pl.shape}\")\n",
    "\n",
    "# singleton works (should say \"already loaded\")\n",
    "df_pd2 = get_pandas_data()  \n",
    "\n",
    "# should NOT reload data (check console)\n",
    "df_pd33 = get_pandas_data()\n",
    "print(f\"Same object? {df_pd is df_pd33}\")  # Should print True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88671bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2c1919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded: (200000, 19)\n",
      "Pandas section dtype: int64\n",
      "Pandas unique sections: [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "Polars section dtype: Int64\n",
      "Polars unique sections: shape: (10,)\n",
      "Series: 'section' [i64]\n",
      "[\n",
      "\t0\n",
      "\t1\n",
      "\t2\n",
      "\t3\n",
      "\t4\n",
      "\t5\n",
      "\t6\n",
      "\t7\n",
      "\t8\n",
      "\t9\n",
      "]\n",
      "============================================================\n",
      "1. STATS SERVICE\n",
      "============================================================\n",
      "Total rows: 200,000\n",
      "Unique companies: 10\n",
      "Top company: ('ADVANCED MICRO DEVICES INC', 38799)\n",
      "\n",
      "2. BENCHMARK SERVICE\n",
      "============================================================\n",
      "Filter rows (name contains 'CORP'): 22.38x faster (Polars)\n",
      "Group by company + count: 3.46x faster (Polars)\n",
      "Calculate avg sentence length: 4.25x faster (Polars)\n",
      "Sort by filing date: 1.98x faster (Polars)\n",
      "Complex query (filter+group+sort+limit): 0.96x faster (Pandas)\n",
      "\n",
      "Overall: Polars is 3.0x faster overall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# All-in-one test cell\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "project_root = Path.cwd().parent if 'test' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "\n",
    "from src.data_loader import get_pandas_data, get_polars_data\n",
    "from src.stats_service import get_overall_stats\n",
    "from src.benchmark_service import run_benchmark\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df_pd = get_pandas_data()\n",
    "df_pl = get_polars_data()\n",
    "print(f\"Loaded: {df_pd.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Check the section column data type and values\n",
    "print(\"Pandas section dtype:\", df_pd['section'].dtype)\n",
    "print(\"Pandas unique sections:\", df_pd['section'].unique()[:10])\n",
    "\n",
    "print(\"\\nPolars section dtype:\", df_pl['section'].dtype)\n",
    "print(\"Polars unique sections:\", df_pl['section'].unique()[:10])\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "df_pd = get_pandas_data()\n",
    "df_pl = get_polars_data()\n",
    "\n",
    "# Test 1: Stats\n",
    "print(\"1. STATS SERVICE\")\n",
    "print(\"=\" * 60)\n",
    "stats = get_overall_stats(df_pl)\n",
    "print(f\"Total rows: {stats['shape']['total_rows']:,}\")\n",
    "print(f\"Unique companies: {stats['unique_values']['unique_companies']}\")\n",
    "print(f\"Top company: {list(stats['top_companies'].items())[0]}\")\n",
    "print()\n",
    "\n",
    "# Test 2: Benchmark\n",
    "print(\"2. BENCHMARK SERVICE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "bench = run_benchmark(df_pd, df_pl)\n",
    "for test in bench['tests']:\n",
    "    print(f\"{test['test']}: {test['speedup']}x faster ({test['winner']})\")\n",
    "print()\n",
    "print(f\"Overall: {bench['summary']['verdict']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ad030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER DETECTION (Full Analysis)\n",
      "============================================================\n",
      "Analyzing all 200k sentences...\n",
      "This may take 30-60 seconds...\n",
      "\n",
      "Extracting text features...\n",
      "Training IsolationForest (contamination=0.05)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joems\\miniconda3\\envs\\flask_eda_lab\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:95: FutureWarning: Function fit_predict is deprecated\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 200,000\n",
      "Outliers detected: 9,980\n",
      "Outlier percentage: 4.99%\n",
      "Algorithm: Isolation Forest\n",
      "\n",
      "============================================================\n",
      "OUTLIER CHARACTERISTICS\n",
      "============================================================\n",
      "Outliers have avg 438 chars vs 155 chars for normal sentences\n",
      "\n",
      "Outlier sentences:\n",
      "  Char count: 1 - 4850 (avg: 437.99)\n",
      "  Word count: 1 - 737 (avg: 64.58)\n",
      "\n",
      "Normal sentences:\n",
      "  Char count avg: 155.13\n",
      "  Word count avg: 23.72\n",
      "\n",
      "============================================================\n",
      "TOP 5 MOST ANOMALOUS SENTENCES\n",
      "============================================================\n",
      "\n",
      "1. Company: ACME UNITED CORP\n",
      "   Section: 10\n",
      "   Length: 4045 chars, 428 words\n",
      "   Anomaly Score: 0.255\n",
      "   Text: Information on the Company's Operations by Business Segments: (All Figures in Thousands) 1997 1996 1995 - --------------------------------------------...\n",
      "\n",
      "\n",
      "2. Company: ACME UNITED CORP\n",
      "   Section: 10\n",
      "   Length: 2374 chars, 237 words\n",
      "   Anomaly Score: 0.249\n",
      "   Text: Other disclosures related to the pension plan follow: 2002 2001 ------------------------------- Changes in benefit obligation Benefit obligation at be...\n",
      "\n",
      "\n",
      "3. Company: ABBOTT LABORATORIES\n",
      "   Section: 3\n",
      "   Length: 2533 chars, 264 words\n",
      "   Anomaly Score: 0.248\n",
      "   Text: Location Segments of Products Produced Abbott Park, Illinois Proprietary Pharmaceutical and Diagnostic Products Alajuela, Costa Rica Vascular Products...\n",
      "\n",
      "\n",
      "4. Company: ABBOTT LABORATORIES\n",
      "   Section: 3\n",
      "   Length: 2382 chars, 255 words\n",
      "   Anomaly Score: 0.247\n",
      "   Text: Location Segments of Products Produced Abbott Park, Illinois Diagnostic Products Alajuela, Costa Rica Vascular Products Altavista, Virginia Nutritiona...\n",
      "\n",
      "\n",
      "5. Company: ABBOTT LABORATORIES\n",
      "   Section: 3\n",
      "   Length: 2485 chars, 264 words\n",
      "   Anomaly Score: 0.247\n",
      "   Text: Location Segments of Products Produced Abbott Park, Illinois Proprietary Pharmaceutical and Diagnostic Products Alcobendas, Spain Non-Reportable Altav...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TEST: OUTLIER DETECTION (Full Analysis)\n",
    "\n",
    "\n",
    "from src.outlier_service import detect_text_outliers\n",
    "\n",
    "print(\"OUTLIER DETECTION (Full Analysis)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Analyzing all 200k sentences...\")\n",
    "print(\"This may take 30-60 seconds...\\n\")\n",
    "\n",
    "# Run full detection with 5% contamination\n",
    "outliers = detect_text_outliers(df_pl, contamination=0.05)\n",
    "\n",
    "# Print summary\n",
    "summary = outliers['detection_summary']\n",
    "print(f\"Total sentences: {summary['total_sentences']:,}\")\n",
    "print(f\"Outliers detected: {summary['outliers_detected']:,}\")\n",
    "print(f\"Outlier percentage: {summary['outlier_percentage']}%\")\n",
    "print(f\"Algorithm: {summary['algorithm']}\")\n",
    "\n",
    "# Print interpretation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER CHARACTERISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(outliers['outlier_characteristics']['interpretation'])\n",
    "\n",
    "# Show outlier vs normal stats\n",
    "outlier_stats = outliers['outlier_characteristics']['outlier_stats']\n",
    "normal_stats = outliers['outlier_characteristics']['normal_stats']\n",
    "\n",
    "print(f\"\\nOutlier sentences:\")\n",
    "print(f\"  Char count: {outlier_stats['char_count']['min']} - {outlier_stats['char_count']['max']} (avg: {outlier_stats['char_count']['mean']})\")\n",
    "print(f\"  Word count: {outlier_stats['word_count']['min']} - {outlier_stats['word_count']['max']} (avg: {outlier_stats['word_count']['mean']})\")\n",
    "\n",
    "print(f\"\\nNormal sentences:\")\n",
    "print(f\"  Char count avg: {normal_stats['char_count']['mean']}\")\n",
    "print(f\"  Word count avg: {normal_stats['word_count']['mean']}\")\n",
    "\n",
    "# Show top 5 most anomalous sentences\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 5 MOST ANOMALOUS SENTENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, outlier in enumerate(outliers['top_10_outliers'][:5], 1):\n",
    "    print(f\"\\n{i}. Company: {outlier['name']}\")\n",
    "    print(f\"   Section: {outlier['section']}\")\n",
    "    print(f\"   Length: {outlier['char_count']} chars, {outlier['word_count']} words\")\n",
    "    print(f\"   Anomaly Score: {outlier['anomaly_score']:.3f}\")\n",
    "    print(f\"   Text: {outlier['sentence'][:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516569ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask_eda_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
